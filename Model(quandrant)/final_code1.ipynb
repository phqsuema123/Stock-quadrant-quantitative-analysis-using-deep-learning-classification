{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f276ba8",
   "metadata": {},
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224f8c3e",
   "metadata": {},
   "source": [
    "a=EMA >=5 RSI>=70\n",
    "b=EMA >=35, >89\n",
    "c=EMA >=89 ; sideway == 5,15,35,89,=>200\n",
    "d= EMA = 89 ; down trend = <=89, <200\n",
    "e= EMA <=85,5; crash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6de8ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    f1_score, accuracy_score, balanced_accuracy_score, matthews_corrcoef,\n",
    "    classification_report, confusion_matrix, log_loss\n",
    ")\n",
    "import plotly.graph_objects as go\n",
    "from cassandra.cluster import Cluster\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d61f6acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = Cluster(['127.0.0.1'])\n",
    "session = cluster.connect()\n",
    "session.set_keyspace('data_stock')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f840f1",
   "metadata": {},
   "source": [
    "eps pe pbv percentyield marketcap\n",
    "\n",
    "\n",
    "ทำไมตั้งแบบนี้\n",
    "\n",
    "EPS>0 = บริษัทมีกำไร (คุณภาพพื้นฐานขั้นต่ำ)\n",
    "\n",
    "P/E 8–25 = กรองถูก/แพงเกินไป (ค่า default ทั่วไป—ปรับได้ตามอุตสาหกรรม)\n",
    "\n",
    "P/BV 0.8–2.5 = ไม่ต่ำกว่าทุนมากเกิน (เสี่ยง) และไม่แพงเวอร์\n",
    "\n",
    "Dividend Yield ≥ 3% (≤ 20%) = ให้ผลตอบแทนเงินสดพอเหมาะ (กัน outlier yield สูงผิดปกติ)\n",
    "\n",
    "Quantile mode ใช้สัดส่วนภายในชุดข้อมูล → ดีสำหรับเปรียบเทียบ “สัมพัทธ์” ในตลาด/อุตสาหกรรมเดียวกัน\n",
    "\n",
    "ถ้าต้องการ “น้ำหนัก” ไม่เท่ากัน (เช่นให้ EPS/PE หนักกว่า PBV/Yield) บอกได้ ผมปรับให้เป็น weighted score ได้เลย เช่น EPS/PE = 2 คะแนน, อีกสองตัว=1 คะแนน แล้วค่อยแปลงเป็น A–E ตามสัดส่วนคะแนนครับ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2ae8fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_fin = session.execute(\"\"\"\n",
    "    SELECT symbol,close, pe, pbv, dividendyield,marketcap,bvps FROM smartset_finan_data ALLOW FILTERING\n",
    "\"\"\")\n",
    "df_financial = pd.DataFrame(rows_fin, columns=[\"symbol\",\"close\",\"pe\",\"pbv\",\"dividendyield\",\"marketcap\",\"bvps\"])\n",
    "df_financial = df_financial.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc40e182",
   "metadata": {},
   "source": [
    "COMFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7810c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_MODE = \"quadrant\"   # \"trend\" (5 กลุ่ม a–e) หรือ \"quadrant\" (25 กลุ่ม A–E×a–e)\n",
    "WINDOW = 60\n",
    "HORIZON = 1\n",
    "EPOCHS = 20\n",
    "BATCH = 256\n",
    "LR = 1e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "PATIENCE = 5\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f47874",
   "metadata": {},
   "source": [
    "Utils: seed + มาตรฐานคอลัมน์"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ac101ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=SEED):\n",
    "    import random\n",
    "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def ensure_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    rename_map = {}\n",
    "    if \"close_price\" in df: rename_map[\"close_price\"] = \"close\"\n",
    "    if \"open_price\"  in df: rename_map[\"open_price\"]  = \"open\"\n",
    "    if \"high_price\"  in df: rename_map[\"high_price\"]  = \"high\"\n",
    "    if \"low_price\"   in df: rename_map[\"low_price\"]   = \"low\"\n",
    "    if \"percentyield\" in df and \"dividendyield\" not in df:\n",
    "        rename_map[\"percentyield\"] = \"dividendyield\"\n",
    "    df = df.rename(columns=rename_map)\n",
    "    for c in [\"open\",\"high\",\"low\",\"close\",\"pe\",\"pbv\",\"dividendyield\",\"marketcap\",\"eps\"]:\n",
    "        if c in df: df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "    return df.sort_values([\"symbol\",\"date\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784ebe94",
   "metadata": {},
   "source": [
    "Indicators & Labels (a–e, A–E, quadrant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc0f8b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ema(df: pd.DataFrame, span: int) -> str:\n",
    "    col = f\"ema_{span}\"\n",
    "    if col not in df.columns:\n",
    "        df[col] = df.groupby(\"symbol\")[\"close\"].transform(lambda s: s.ewm(span=span, adjust=False).mean())\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bb7d6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rsi(df: pd.DataFrame, period: int = 14) -> str:\n",
    "    col = \"rsi\"\n",
    "    if col in df.columns: return col\n",
    "    g = df.groupby(\"symbol\")[\"close\"]\n",
    "    delta = g.transform(lambda s: s.diff())\n",
    "    gain = delta.clip(lower=0.0)\n",
    "    loss = -delta.clip(upper=0.0)\n",
    "    avg_gain = gain.groupby(df[\"symbol\"]).transform(lambda s: s.ewm(alpha=1/period, adjust=False).mean())\n",
    "    avg_loss = loss.groupby(df[\"symbol\"]).transform(lambda s: s.ewm(alpha=1/period, adjust=False).mean())\n",
    "    rs = avg_gain / avg_loss.replace(0, np.nan)\n",
    "    df[col] = 100 - (100/(1+rs))\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f7cd048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_trend_ae(df: pd.DataFrame, sideway_band_pct=0.015, rsi_hi=70, rsi_lo=30) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    e5   = add_ema(df, 5)\n",
    "    e15  = add_ema(df, 15)\n",
    "    e35  = add_ema(df, 35)\n",
    "    e89  = add_ema(df, 89)\n",
    "    e200 = add_ema(df, 200)\n",
    "    rsi  = add_rsi(df, 14)\n",
    "\n",
    "    a_mask = (df[\"close\"] >= df[e5]) & (df[rsi] >= rsi_hi)\n",
    "    b_mask = (df[\"close\"] >= df[e35]) & (df[e35] >= df[e89])\n",
    "    short_pack = df[[e5, e15, e35, e89]].copy()\n",
    "    band = (short_pack.max(axis=1) - short_pack.min(axis=1)) / short_pack.mean(axis=1)\n",
    "    c_mask = (df[\"close\"] >= df[e89]) & (band <= sideway_band_pct)\n",
    "    d_mask = (df[\"close\"] < df[e89]) & (df[\"close\"] < df[e200]) & (df[e89] < df[e200])\n",
    "    e_mask = (\n",
    "        (df[\"close\"] < df[e5]) &\n",
    "        (df[e5] < df[e15]) & (df[e15] < df[e35]) &\n",
    "        (df[e35] < df[e89]) & (df[e89] < df[e200]) &\n",
    "        (df[rsi] <= rsi_lo)\n",
    "    )\n",
    "    out = pd.Series(index=df.index, dtype=\"object\")\n",
    "    for lab, m in [(\"e\", e_mask), (\"d\", d_mask), (\"a\", a_mask), (\"b\", b_mask), (\"c\", c_mask)]:\n",
    "        out = out.mask(out.notna(), out)\n",
    "        out = out.where(~m, lab)\n",
    "    df[\"trend_bucket\"] = out.fillna(\"c\").astype(\"category\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd1829a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_financial_level(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    if \"eps\" not in df.columns and {\"close\",\"pe\"}.issubset(df.columns):\n",
    "        df[\"eps\"] = np.where((df[\"pe\"]>0) & df[\"close\"].notna(), df[\"close\"]/df[\"pe\"], np.nan)\n",
    "    s_eps = df[\"eps\"] > 0\n",
    "    s_pe  = (df[\"pe\"] >= 8) & (df[\"pe\"] <= 25)\n",
    "    s_pbv = (df[\"pbv\"] >= 0.8) & (df[\"pbv\"] <= 2.5)\n",
    "    s_yld = (df[\"dividendyield\"] >= 3.0) & (df[\"dividendyield\"] <= 20.0)\n",
    "    score = s_eps.fillna(False).astype(int) + s_pe.fillna(False).astype(int) + s_pbv.fillna(False).astype(int) + s_yld.fillna(False).astype(int)\n",
    "    fin = np.where(score==4,\"A\", np.where(score==3,\"B\", np.where(score==2,\"C\", np.where(score==1,\"D\",\"E\"))))\n",
    "    df[\"financial_level\"] = pd.Categorical(fin, categories=list(\"ABCDE\"), ordered=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a1f7b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_quadrant(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = ensure_cols(df)\n",
    "    df = label_trend_ae(df)\n",
    "    df = label_financial_level(df)\n",
    "    df[\"quadrant\"] = (df[\"financial_level\"].astype(str) + df[\"trend_bucket\"].astype(str)).astype(\"category\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4629dfb",
   "metadata": {},
   "source": [
    "เติมฟีเจอร์ลำดับเวลา (ATR/Vol/Gap/Range/Bollinger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a227eb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_seq_features(fe: pd.DataFrame) -> pd.DataFrame:\n",
    "    fe = fe.copy()\n",
    "    if \"atr\" not in fe.columns:\n",
    "        def _atr(g, p=14):\n",
    "            pc = g[\"close\"].shift(1)\n",
    "            tr = pd.concat([(g[\"high\"]-g[\"low\"]).abs(), (g[\"high\"]-pc).abs(), (g[\"low\"]-pc).abs()], axis=1).max(axis=1)\n",
    "            return tr.ewm(alpha=1/p, adjust=False).mean()\n",
    "        fe[\"atr\"] = fe.groupby(\"symbol\", group_keys=False).apply(_atr)\n",
    "    if \"vol_20\" not in fe.columns:\n",
    "        ret = fe.groupby(\"symbol\")[\"close\"].pct_change()\n",
    "        fe[\"vol_20\"] = ret.groupby(fe[\"symbol\"]).rolling(20).std().reset_index(level=0, drop=True)\n",
    "    if \"gap_pct\" not in fe.columns and {\"open\",\"close\"}.issubset(fe.columns):\n",
    "        prev_close = fe.groupby(\"symbol\")[\"close\"].shift(1)\n",
    "        fe[\"gap_pct\"] = fe[\"open\"]/prev_close - 1.0\n",
    "    if \"range_pct\" not in fe.columns and {\"high\",\"low\",\"close\"}.issubset(fe.columns):\n",
    "        fe[\"range_pct\"] = (fe[\"high\"]-fe[\"low\"]) / fe[\"close\"]\n",
    "    if \"bb_width\" not in fe.columns or \"bb_pos\" not in fe.columns:\n",
    "        mid = fe.groupby(\"symbol\")[\"close\"].rolling(20).mean().reset_index(level=0, drop=True)\n",
    "        std = fe.groupby(\"symbol\")[\"close\"].rolling(20).std().reset_index(level=0, drop=True)\n",
    "        upper = mid + 2*std; lower = mid - 2*std\n",
    "        fe[\"bb_width\"] = (upper - lower) / mid\n",
    "        fe[\"bb_pos\"]   = (fe[\"close\"] - lower) / (upper - lower)\n",
    "    return fe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5decf8c6",
   "metadata": {},
   "source": [
    "Dataset & Collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bda7fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqDS(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, seq_cols, static_cols):\n",
    "        self.df = df.sort_values([\"symbol\",\"date\"]).reset_index()\n",
    "        self.seq_cols = seq_cols; self.static_cols = static_cols\n",
    "        self.samples=[]\n",
    "        for sym, g in self.df.groupby(\"symbol\"):\n",
    "            for i in range(WINDOW+HORIZON, len(g)):\n",
    "                row_idx = g.loc[i, \"index\"]\n",
    "                win_idx = g.loc[i-WINDOW-HORIZON:i-HORIZON-1, \"index\"].values\n",
    "                if not np.isnan(self.df.loc[row_idx,\"y\"]):\n",
    "                    self.samples.append((win_idx, row_idx))\n",
    "    def __len__(self): return len(self.samples)\n",
    "    def __getitem__(self, i):\n",
    "        idx_win, idx_row = self.samples[i]\n",
    "        seq = self.df.loc[idx_win, self.seq_cols].fillna(seq_med).astype(float)\n",
    "        seq = (seq - seq_mu) / seq_sd\n",
    "        x_seq = torch.tensor(seq.values, dtype=torch.float32)\n",
    "        if self.static_cols:\n",
    "            stat = self.df.loc[idx_row, self.static_cols].fillna(stat_med).astype(float)\n",
    "            stat = (stat - stat_mu) / stat_sd\n",
    "            x_static = torch.tensor(stat.values, dtype=torch.float32)\n",
    "        else:\n",
    "            x_static = torch.empty(0)\n",
    "        y = int(self.df.loc[idx_row,\"y\"])\n",
    "        return x_seq, x_static, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ace4cf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    xs, ss, ys = zip(*batch)\n",
    "    xs = torch.stack(xs)\n",
    "    ss = torch.stack(ss) if len(ss[0]) else torch.empty((len(batch),0))\n",
    "    ys = torch.tensor(ys, dtype=torch.long)\n",
    "    return xs, ss, ys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45971b3f",
   "metadata": {},
   "source": [
    "โมเดล TCN two-tower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e287f291",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chomp1d(nn.Module):\n",
    "    def __init__(self, s): super().__init__(); self.s=s\n",
    "    def forward(self,x): return x[...,:-self.s].contiguous()\n",
    "\n",
    "class TBlock(nn.Module):\n",
    "    def __init__(self, c_in, c_out, k, d, p=0.2):\n",
    "        super().__init__()\n",
    "        pad=(k-1)*d\n",
    "        self.net=nn.Sequential(\n",
    "            nn.Conv1d(c_in,c_out,k,padding=pad,dilation=d),Chomp1d(pad),nn.ReLU(),nn.Dropout(p),\n",
    "            nn.Conv1d(c_out,c_out,k,padding=pad,dilation=d),Chomp1d(pad),nn.ReLU(),nn.Dropout(p),\n",
    "        )\n",
    "        self.down=nn.Conv1d(c_in,c_out,1) if c_in!=c_out else nn.Identity()\n",
    "    def forward(self,x): y=self.net(x); return torch.relu(y+self.down(x))\n",
    "\n",
    "class TCN(nn.Module):\n",
    "    def __init__(self, in_feat, n_classes, static_dim=0, chans=(64,64,128), k=3, p=0.2):\n",
    "        super().__init__()\n",
    "        layers=[]; c_in=in_feat\n",
    "        for i,c in enumerate(chans):\n",
    "            layers.append(TBlock(c_in,c,k,d=2**i,p=p)); c_in=c\n",
    "        self.tcn=nn.Sequential(*layers)\n",
    "        self.pool=nn.AdaptiveAvgPool1d(1)\n",
    "        self.head=nn.Sequential(\n",
    "            nn.Linear(c_in+static_dim,256), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(256,n_classes)\n",
    "        )\n",
    "    def forward(self,x_seq,x_static=None):\n",
    "        z=self.tcn(x_seq.transpose(1,2))   # [B,F,T]\n",
    "        z=self.pool(z).squeeze(-1)         # [B,C]\n",
    "        if x_static is not None and x_static.numel()>0:\n",
    "            z=torch.cat([z,x_static],dim=1)\n",
    "        return self.head(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277c0355",
   "metadata": {},
   "source": [
    "Train TCN + ดึงผลทำนายสำหรับเทียบ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "744eb7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tcn_and_predict(df: pd.DataFrame):\n",
    "    set_seed(SEED)\n",
    "    fe = make_quadrant(df)\n",
    "    fe = enrich_seq_features(fe)\n",
    "    fe = fe.sort_values([\"symbol\",\"date\"]).reset_index(drop=True)\n",
    "\n",
    "    SEQ_COLS = [c for c in [\"close\",\"ema_5\",\"ema_15\",\"ema_35\",\"ema_89\",\"ema_200\",\"rsi\",\"bb_width\",\"bb_pos\",\"atr\",\"vol_20\",\"gap_pct\",\"range_pct\"] if c in fe.columns]\n",
    "    STATIC_COLS = [c for c in [\"eps\",\"pe\",\"pbv\",\"dividendyield\",\"marketcap\"] if c in fe.columns]\n",
    "\n",
    "    if TARGET_MODE == \"trend\":\n",
    "        classes = sorted(fe[\"trend_bucket\"].astype(str).unique())\n",
    "        fe[\"y\"] = fe[\"trend_bucket\"].astype(str).map({c:i for i,c in enumerate(classes)})\n",
    "    else:\n",
    "        classes = sorted(fe[\"quadrant\"].astype(str).unique())\n",
    "        fe[\"y\"] = fe[\"quadrant\"].astype(str).map({c:i for i,c in enumerate(classes)})\n",
    "\n",
    "    cut = fe[\"date\"].quantile(0.8)\n",
    "    df_tr, df_va = fe[fe[\"date\"]<=cut].copy(), fe[fe[\"date\"]>cut].copy()\n",
    "\n",
    "    global seq_mu, seq_sd, stat_mu, stat_sd, seq_med, stat_med\n",
    "    seq_mu, seq_sd = df_tr[SEQ_COLS].mean(), df_tr[SEQ_COLS].std().replace(0,1.0)\n",
    "    seq_med = df_tr[SEQ_COLS].median()\n",
    "    if STATIC_COLS:\n",
    "        stat_mu = df_tr[STATIC_COLS].mean()\n",
    "        stat_sd = df_tr[STATIC_COLS].std().replace(0,1.0)\n",
    "        stat_med = df_tr[STATIC_COLS].median()\n",
    "    else:\n",
    "        stat_mu = pd.Series(dtype=float); stat_sd = pd.Series(dtype=float); stat_med = pd.Series(dtype=float)\n",
    "\n",
    "    tr_ds, va_ds = SeqDS(df_tr, SEQ_COLS, STATIC_COLS), SeqDS(df_va, SEQ_COLS, STATIC_COLS)\n",
    "    tr_ld = DataLoader(tr_ds, batch_size=BATCH, shuffle=True, collate_fn=collate_fn)\n",
    "    va_ld = DataLoader(va_ds, batch_size=BATCH, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model=TCN(in_feat=len(SEQ_COLS), n_classes=len(classes), static_dim=len(STATIC_COLS)).to(device)\n",
    "\n",
    "    cc=np.bincount([y for *_,y in tr_ds], minlength=len(classes))\n",
    "    w=(cc.sum()/(cc+1e-6)); w=torch.tensor(w/w.mean(), dtype=torch.float32, device=device)\n",
    "    crit=nn.CrossEntropyLoss(weight=w)\n",
    "    opt=torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "    def evaluate(ld):\n",
    "        model.eval(); ys=[]; ps=[]; probs=[]\n",
    "        with torch.no_grad():\n",
    "            for xs,ss,y in ld:\n",
    "                xs, y = xs.to(device), y.to(device)\n",
    "                ss = ss.to(device) if len(STATIC_COLS)>0 else None\n",
    "                logits = model(xs, ss)\n",
    "                pred = logits.argmax(1)\n",
    "                ys.append(y.cpu().numpy()); ps.append(pred.cpu().numpy())\n",
    "                probs.append(torch.softmax(logits,1).cpu().numpy())\n",
    "        y=np.concatenate(ys); p=np.concatenate(ps); pr=np.concatenate(probs)\n",
    "        return f1_score(y,p,average=\"macro\"), y, p, pr\n",
    "\n",
    "    BEST=-1; patience=0\n",
    "    for ep in range(1, EPOCHS+1):\n",
    "        model.train(); tot=0.0; n=0\n",
    "        for xs,ss,y in tr_ld:\n",
    "            xs,y=xs.to(device),y.to(device)\n",
    "            ss=ss.to(device) if len(STATIC_COLS)>0 else None\n",
    "            opt.zero_grad()\n",
    "            logits=model(xs,ss)\n",
    "            loss=crit(logits,y); loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(),1.0)\n",
    "            opt.step()\n",
    "            tot += loss.item()*xs.size(0); n += xs.size(0)\n",
    "        f1, yv, pv, _ = evaluate(va_ld)\n",
    "        print(f\"Epoch {ep:02d}  train_loss={tot/max(1,n):.4f}  val_macroF1={f1:.4f}\")\n",
    "        if f1>BEST+1e-4:\n",
    "            BEST=f1; patience=0; torch.save(model.state_dict(),\"tcn_best.pt\")\n",
    "        else:\n",
    "            patience+=1\n",
    "            if patience>=PATIENCE:\n",
    "                print(\"Early stop\"); break\n",
    "\n",
    "    model.load_state_dict(torch.load(\"tcn_best.pt\", map_location=device))\n",
    "    f1, y_true_val, y_pred_dl, y_prob_dl = evaluate(va_ld)\n",
    "    print(\"Best Macro-F1:\", f1)\n",
    "    print(classification_report(y_true_val, y_pred_dl, target_names=classes))\n",
    "    return model, classes, (y_true_val, y_pred_dl, y_prob_dl), df_va.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df267c06",
   "metadata": {},
   "source": [
    "Financial-only Logistic Regression baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ea75758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def financial_lr_baseline(fe_df: pd.DataFrame, classes):\n",
    "    FIN_FEATS = [\"eps\",\"pe\",\"pbv\",\"dividendyield\",\"marketcap\",\"bvps\"]\n",
    "    fe_df = fe_df.copy()\n",
    "    if \"dividendyield\" not in fe_df.columns and \"percentyield\" in fe_df.columns:\n",
    "        fe_df[\"dividendyield\"] = fe_df[\"percentyield\"]\n",
    "    if \"eps\" not in fe_df.columns and {\"close\",\"pe\"}.issubset(fe_df.columns):\n",
    "        fe_df[\"eps\"] = np.where((fe_df[\"pe\"]>0) & fe_df[\"close\"].notna(), fe_df[\"close\"]/fe_df[\"pe\"], np.nan)\n",
    "\n",
    "    X_cols = [c for c in FIN_FEATS if c in fe_df.columns]\n",
    "    if not X_cols:\n",
    "        raise ValueError(\"ไม่พบคอลัมน์ financial ในชุดข้อมูล\")\n",
    "\n",
    "    cut = fe_df[\"date\"].quantile(0.8)\n",
    "    tr, va = fe_df[fe_df[\"date\"]<=cut].copy(), fe_df[fe_df[\"date\"]>cut].copy()\n",
    "\n",
    "    fill_tr = tr[X_cols].median(numeric_only=True)\n",
    "    Xtr = tr[X_cols].fillna(fill_tr).astype(float)\n",
    "    Xva = va[X_cols].fillna(fill_tr).astype(float)\n",
    "    ytr = tr[\"y\"].values\n",
    "    yva = va[\"y\"].values\n",
    "\n",
    "    scaler = StandardScaler().fit(Xtr)\n",
    "    Xtr_s = scaler.transform(Xtr); Xva_s = scaler.transform(Xva)\n",
    "\n",
    "    lr = LogisticRegression(multi_class=\"multinomial\", max_iter=1000, class_weight=\"balanced\")\n",
    "    lr.fit(Xtr_s, ytr)\n",
    "    pred_lr = lr.predict(Xva_s)\n",
    "    prob_lr = lr.predict_proba(Xva_s)\n",
    "\n",
    "    print(\"\\n[Financial-only LR]\")\n",
    "    print(\"Macro-F1:\", f1_score(yva, pred_lr, average=\"macro\"))\n",
    "    print(classification_report(yva, pred_lr, target_names=classes))\n",
    "    print(\"Confusion matrix:\\n\", confusion_matrix(yva, pred_lr))\n",
    "    return (yva, pred_lr, prob_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4634bb0",
   "metadata": {},
   "source": [
    "Compare Scores (DL vs LR) + McNemar + Bootstrap CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bf24c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(dl_tuple, lr_tuple, classes):\n",
    "    y_true_val, y_pred_dl, y_prob_dl = dl_tuple\n",
    "    yva, pred_lr, prob_lr = lr_tuple\n",
    "\n",
    "    n = min(len(y_true_val), len(yva))\n",
    "    yt = y_true_val[:n]\n",
    "    p_dl = y_pred_dl[:n]; pr_dl = y_prob_dl[:n]\n",
    "    p_lr = pred_lr[:n];   pr_lr = prob_lr[:n]\n",
    "\n",
    "    def summarize(y_true, y_pred, y_prob, name):\n",
    "        return {\n",
    "            \"model\": name,\n",
    "            \"macro_f1\": f1_score(y_true, y_pred, average=\"macro\"),\n",
    "            \"balanced_acc\": balanced_accuracy_score(y_true, y_pred),\n",
    "            \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "            \"mcc\": matthews_corrcoef(y_true, y_pred),\n",
    "            \"log_loss\": (log_loss(y_true, y_prob, labels=list(range(len(classes)))) \n",
    "                         if y_prob is not None and y_prob.shape[1]==len(classes) else np.nan)\n",
    "        }\n",
    "\n",
    "    scores = pd.DataFrame([\n",
    "        summarize(yt, p_lr, pr_lr, \"Financial-only LR\"),\n",
    "        summarize(yt, p_dl, pr_dl, \"Deep Learning (TCN)\")\n",
    "    ])\n",
    "    display(scores)\n",
    "\n",
    "    from scipy.stats import chi2, binomtest\n",
    "    agree_dl = (p_dl == yt); agree_lr = (p_lr == yt)\n",
    "    b = int(((agree_dl==1) & (agree_lr==0)).sum())\n",
    "    c = int(((agree_dl==0) & (agree_lr==1)).sum())\n",
    "    N = b + c\n",
    "    if N > 0:\n",
    "        stat = (abs(b - c) - 1)**2 / (b + c)\n",
    "        pval = 1 - chi2.cdf(stat, df=1)\n",
    "        p_exact = binomtest(min(b,c), n=N, p=0.5, alternative=\"two-sided\").pvalue\n",
    "        print(f\"\\nMcNemar: b={b}, c={c}, chi2={stat:.3f}, p={pval:.4f}, exact_p={p_exact:.4f}\")\n",
    "    else:\n",
    "        print(\"\\nMcNemar: b+c=0 (คำตอบสองโมเดลตรงกันเกือบหมด)\")\n",
    "\n",
    "    rng = np.random.default_rng(123)\n",
    "    diffs = []\n",
    "    for _ in range(1000):\n",
    "        idx = rng.integers(0, n, n)\n",
    "        diffs.append(\n",
    "            f1_score(yt[idx], p_dl[idx], average=\"macro\")\n",
    "            - f1_score(yt[idx], p_lr[idx], average=\"macro\")\n",
    "        )\n",
    "    lo, hi = np.percentile(diffs, [2.5, 97.5])\n",
    "    print(f\"ΔMacro-F1 (DL − LR) bootstrap 95% CI: [{lo:.4f}, {hi:.4f}]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deef056a",
   "metadata": {},
   "source": [
    " การใช้งาน "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8c5628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# สมมติคุณมี DataFrame 'df' ที่รวมราคา+พื้นฐาน: columns ต้องมีอย่างน้อย symbol, date, open, high, low, close\n",
    "# 1) ฝึก DL และดึงผล val\n",
    "# model, classes, dl_tuple, val_df = train_tcn_and_predict(df)\n",
    "# 2) ทำ baseline สถิติแบบใช้เฉพาะ financial\n",
    "# lr_tuple = financial_lr_baseline(val_df.assign(**{}).pipe(lambda d: pd.concat([d,], axis=1)) if True else val_df, classes)\n",
    "#    (หมายเหตุ: lr ใช้ทั้ง train/val แยกในฟังก์ชันแล้วจาก fe_df ภายใน pipeline ก่อนหน้า)\n",
    "# ทางที่ง่ายกว่า: ใช้ fe_df ตัวเดียวกับใน train_tcn_and_predict:\n",
    "#   ให้สร้าง fe_df = make_quadrant(df) ก่อน แล้วส่งเข้า financial_lr_baseline(fe_df, classes)\n",
    "\n",
    "# ตัวอย่างสั้น:\n",
    "# fe_df = make_quadrant(df)\n",
    "# lr_tuple = financial_lr_baseline(fe_df, classes)\n",
    "# compare_models(dl_tuple, lr_tuple, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8a4c49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
